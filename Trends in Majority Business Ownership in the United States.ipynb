{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Ownership Trends in the United States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foundational Questions: \n",
    "1. How is the minority representation in business ownership throughout industries changing?\n",
    "2. Are there any states that have higher than average minority business ownership across all classes?\n",
    "3. What other ways can businesses be clustered besides sector, and what is the minority breakdown across these clusters?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project I wil be examining the trends in business ownership in the United States. The data for this project was acquired through the United States Census Bureau's Survey of Business Owners. The Survey of Business Owners is conducted every 5 years. The Census Bureau publishes the summary statistics for each survey based on traits like race, ethnicity, education level, and whether a person was born in the United States. I will begin the project looking at trends in this data for the survey years 2002, 2007, and 2012. This data can be found here: https://www.census.gov/programs-surveys/sbo/data/tables.html\n",
    "\n",
    "The Census Bureau has also releases a microdata sample for the year 2007. This sample contains data regarding the characteristics of individual businesses and their respective owners for about 1.5 million businesses. To protect the identity of the businesses and their owners artificial noise is inserted into the dataset. Notably, this dataset also contains geographic information about each business as well as estimated for their employees, payroll, and receivables. This dataset can be found here: https://www.census.gov/content/census/en/data/datasets/2007/econ/sbo/2007-sbo-pums.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import wget\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import chart_studio.plotly as py\n",
    "import seaborn as sns\n",
    "\n",
    "from kmodes.kprototypes import KPrototypes\n",
    "from sklearn import preprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Reading in the Data\n",
    "The government API for the Survey of Business Owners is still in its fledgling stages. As of now the only year that is available in the API. Below is an example of what the API call would look like. However, for consistency purposes, I scraped the .dat files for each of the three years from the website directly rather that going through the API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key='c8911a06059ba719933e4ed122c676f87fbf0b8a'\n",
    "\n",
    "response=requests.get('https://api.census.gov/data/2012/sbo/cscb?get=FIRMALL,FIRMPDEMP_PCT_S,RCPALL,FIRMNOPD_S,RCPNOPD,FIRMNOPD_PCT,FIRMNOPD,EMP_S,PAYANN,RCPPDEMP,RCPPDEMP_F,RCPNOPD_PCT_S,FIRMALL_S,SPOUSES,CBGROUP_TTL,EMP,RCPPDEMP_S,EMP_PCT,YEAR,RCPNOPD_PCT,FIRMNOPD_PCT_S,EMP_PCT_S,CBGROUP,NAICS2012_TTL,PAYANN_PCT_S,PAYANN_S,GEO_TTL,RCPALL_PCT,RCPPDEMP_PCT_S,PAYANN_PCT,SPOUSES_TTL,RCPALL_PCT_S,RCPNOPD_S,FIRMPDEMP_PCT,FIRMPDEMP_S,FIRMPDEMP,FIRMALL_PCT,FIRMALL_PCT_S,RCPPDEMP_PCT,COUNTY&for=us:*&key=c8911a06059ba719933e4ed122c676f87fbf0b8a')\n",
    "print(response.text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a) Reading DAT files from the Census Bureau website\n",
    "The process had three parts: iterate through each of the files, download the zip files, then unzip them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zips():\n",
    "    \"\"\"Downloads all the the table zip files for the years 2002, 2007 and 2012\"\"\"\n",
    "    base_url = r'https://www2.census.gov/econ{0}/SB/sector00/SB{1}00CSCBO0{2}.zip'\n",
    "    for i in range(2002, 2013, 5):\n",
    "        year = str(i)\n",
    "        for j in range(1,10): #Each year had nine files numbered as such\n",
    "            file_num = str(j)\n",
    "            updated_url = base_url.format(year, year[-2:], file_num)\n",
    "            #path to save the files my filesystem.\n",
    "            path = r'./data/zips/{0}/SB{1}00CSCBO0{2}.zip'.format(year, year[-2:], file_num)\n",
    "            \n",
    "            download_url(updated_url, path)\n",
    "            \n",
    "            \n",
    "def download_url(url, save_path, chunk_size=128):\n",
    "    \"\"\"Function to download a zip file from a url and save it to a local folder\"\"\"\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open(save_path, 'wb') as fd: \n",
    "        #Files are too large to download directly with wget, so we downoad them in chunks\n",
    "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "            fd.write(chunk)\n",
    "                    \n",
    "def unzip():\n",
    "    \"\"\"Unzips all the files in the data folders\"\"\"\n",
    "    file_names = glob.glob(\"./data/*/*/*.zip\")\n",
    "    for file in file_names:\n",
    "        try:\n",
    "            with zipfile.ZipFile(file, 'r') as zip_ref:\n",
    "                zip_ref.extractall(file[0:7] + 'unzipped' + file[11:17])\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "\n",
    "get_zips()\n",
    "unzip()           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b) Combining the files and saving them into a dataframe for each year \n",
    "Combining the data for each year in a way that made sense for analyzing trends was a considerable challenge. The structure of the data for each of the three years were different. Specifically, all the columns had different names and for some years multiple columns were combined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_tables_by_year(year_str, valid_cols, secondary_cols):\n",
    "    year_df = pd.DataFrame()\n",
    "    \n",
    "    file_names = glob.glob(\"./data/unzipped/{}/*.dat\".format(year_str))\n",
    "        \n",
    "    for file in file_names:\n",
    "        #opens each file and reads it into a dataframe. Data is separated using a \"|\"\n",
    "        infile = open(file, 'r')\n",
    "        data = []\n",
    "        for line in infile:\n",
    "            data.append(line.split('|'))\n",
    "                \n",
    "        rows = data[1:]\n",
    "        cols = data[0]\n",
    "        dataframe = pd.DataFrame(rows, columns=cols)\n",
    "            \n",
    "        #changes the structure of the dataframe so the feature column will be split into two columns, the \n",
    "        #column name and the column value. This is done so that many different types of tables with different \n",
    "        #variables can be combined into one dataframe. \n",
    "        df_cols = []\n",
    "        df_col = \"\"\n",
    "        for col in dataframe.columns:\n",
    "            if col in secondary_cols:\n",
    "                df_cols = valid_cols + [col]\n",
    "                df_col = col\n",
    "                break\n",
    "\n",
    "        dataframe[\"Column Val\"] = dataframe[col]\n",
    "        dataframe[\"Col Type\"] = df_col\n",
    "        \n",
    "            \n",
    "        #Final step: concatenates the individual dataframe read from the file into the master dataframe\n",
    "        var_df = dataframe[valid_cols + [\"Column Val\"] + [\"Col Type\"]]\n",
    "        year_df = pd.concat([year_df, var_df])\n",
    "            \n",
    "    return year_df\n",
    "\n",
    "\n",
    "#Defining column structure for each year\n",
    "valid_cols_2002 = ['NAICS2002_MEANING','YEAR', 'OWNALL', 'OWNALL_PCT']\n",
    "secondary_cols_2002 = ['PRMINC_MEANING', 'PFNCT_MEANING', 'VETSPECIFIC_MEANING', 'OWNRAGE_MEANING',\n",
    "                 'YRACQBUS_MEANING', 'HRSWRKD_MEANING', 'ACQBUS_MEANING', 'EDUC_MEANING', 'OWNER_SEX_GROUP_MEANING']\n",
    "\n",
    "valid_cols_2007 = ['NAICS2007_MEANING', 'CBOGROUP_MEANING', 'CBOSEX_MEANING',\n",
    "              'YEAR', 'OWNALL', 'OWNALL_PCT']\n",
    "secondary_cols_2007 = ['PRMINC_MEANING', 'PFNCT_MEANING', 'VETSPECIFIC_MEANING', 'OWNRAGE_MEANING',\n",
    "                 'YRACQBUS_MEANING', 'HRSWRKD_MEANING', 'ACQBUS_MEANING', 'EDUC_MEANING']\n",
    "\n",
    "valid_cols_2012 = ['NAICS2012_TTL', 'CBOGROUP_TTL', 'CBOSEX_TTL','YEAR', 'OWNALL', 'OWNALL_PCT']\n",
    "secondary_cols_2012 = ['PRMINC_TTL', 'PFNCT_TTL', 'VETSPECIFIC_TTL', 'OWNRAGE_TTL',\n",
    "                 'YRACQBUS_TTL', 'HRSWRKD_TTL', 'ACQBUS_TTL', 'EDUC_TTL']\n",
    "\n",
    "#creating dataframes for each year\n",
    "df_2002 = combine_tables_by_year('2002', valid_cols_2002, secondary_cols_2002)\n",
    "df_2002['OWNALL'] = pd.to_numeric(df_2002['OWNALL'])\n",
    "df_2007 = combine_tables_by_year('2007', valid_cols_2007, secondary_cols_2007)\n",
    "df_2007['OWNALL'] = pd.to_numeric(df_2007['OWNALL'])\n",
    "df_2012 = combine_tables_by_year('2012', valid_cols_2012, secondary_cols_2012)\n",
    "df_2012['OWNALL'] = pd.to_numeric(df_2012['OWNALL'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2002.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2007.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2012.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c) The  2007 Microdata sample\n",
    "Unfortunately, the Census Bureau does not provide the characteristic dart for each of the roughly 70 million businesses in the United States for each year the survey of business owners is conducted. Rather, they make available to the public one \"microdata\" sample of 1.5 million businesses from the year 2007. This is the most granular dataset they provide, as it contains detailed information about each business's size, performance, and ownership. It also gives state level data, a useful tool when looking for geographic differences in business ownership trends. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_2007_df = pd.read_csv('./data/pums.csv')\n",
    "full_2007_df.head()\n",
    "print(len(full_2007_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the necessary columns\n",
    "full_df = full_2007_df[['FIPST', 'SECTOR','EMPLOYMENT_NOISY','PAYROLL_NOISY' ,'RECEIPTS_NOISY' ,'PCT1' ,'ETH1' ,\n",
    "                        'RACE1' ,'SEX1' ,'VET1','FOUNDED1' ,'PURCHASED1' ,'INHERITED1', 'RECEIVED1', 'ACQUIRENR1',\n",
    "                        'ACQYR1', 'PROVIDE1', 'MANAGE1', 'FINANCIAL1', 'FNCTNABV1', 'FNCTNR1','HOURS1', 'PRMINC1', \n",
    "                        'SELFEMP1', 'EDUC1', 'AGE1', 'BORNUS1', 'DISVET1', 'ESTABLISHED', 'SCAMOUNT', 'FEDERAL',\n",
    "                        'STATELOCAL', 'INDIVIDUALS', 'FAMILYBUS', 'ECOMMPCT', 'HUSBWIFE', 'HOMEBASED', 'FRANCHISE']]\n",
    "\n",
    "analy_df = full_df[full_df['PCT1'] > 50]\n",
    "analy_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the 2007 PUMS data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = analy_df.copy()\n",
    "\n",
    "\n",
    "### Mapping catergorical data for all the columns\n",
    "sector_map = {11:'Agriculture, Forestry, Fishing and Hunting', 21:'Mining', 22:'Utilities', 23:'Construction',\n",
    "              31:'Manufacturing', 32:'Manufacturing', 33:'Manufacturing', 42:'Wholesale Trade', 44:'Retail Trade',\n",
    "              45:'Retail Trade', 48:'Transportation and Warehousing', 49:'Transportation and Warehousing', 51:'Information',\n",
    "              52:'Finance and Insurance', 53:'Real Estate Rental and Leasing', 54:'Professional, Scientific, and Technical Services',\n",
    "              55:'Management of Companies and Enterprises', 56:'Administrative and Support and Waste Management and Remediation Services',\n",
    "              61:'Educational Services', 62:'Health Care and Social Assistance', 71:'Arts, Entertainment, and Recreation', \n",
    "              72:'Arts, Entertainment, and Recreation', 81:'Other Services', 92:'Public Administration'}\n",
    "\n",
    "general_map = {0: \"Not Reported\", 1: 'Yes', 2:'No'}\n",
    "\n",
    "education_map = {0: \"Not Reported\", 1: 'Less than High School', 2:'High School', 3:'Technical School',\n",
    "                 4:'Some College',5:'Associates',6: 'Bachelors', 7:'Grad School'}\n",
    "\n",
    "analysis_df['FAMILYBUS'] = analysis_df['FAMILYBUS'].map(general_map)\n",
    "analysis_df['BORNUS1'] = analysis_df['BORNUS1'].map(general_map)\n",
    "analysis_df['VET1'] = analysis_df['VET1'].map(general_map)\n",
    "analysis_df['HOMEBASED'] = analysis_df['HOMEBASED'].map(general_map)\n",
    "analysis_df['FRANCHISE'] = analysis_df['FRANCHISE'].map(general_map)\n",
    "analysis_df['EDUC1'] = analysis_df['EDUC1'].map(education_map)\n",
    "\n",
    "\n",
    "\n",
    "###REformatting the State and Race columns so they are more understadable.\n",
    "states = [\"AL\", \"AK\", \"American Samoa\", \"AZ\", \"AR\", \"CA\", \"\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \n",
    "          \"Guam\", \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "          \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "          \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", 'Puerto Rico', \"RI\", \"SC\", \n",
    "          \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"Virgin Islands\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "\n",
    "state_vals = [float(i) for i in range(1, 57)]\n",
    "\n",
    "state_map = dict(zip(state_vals, states))\n",
    "\n",
    "analysis_df['RACE ETH'] = analysis_df['RACE1'] + analysis_df['ETH1']\n",
    "\n",
    "def race_eth(string):\n",
    "    if string[-1] == 'H':\n",
    "        return \"Hispanic\"\n",
    "    elif string[0] == 'W':\n",
    "        return \"White\"\n",
    "    elif string[0] == 'A':\n",
    "        return \"Asian\"\n",
    "    elif string[0] == 'B':\n",
    "        return \"Black or African American\"\n",
    "    elif string[0] == 'I':\n",
    "        return \"American Indian or Alaska Native\"\n",
    "    elif string[0] == 'P':\n",
    "        return \"Pacific Islander\"\n",
    "    \n",
    "analysis_df['RACE ETH'] = analysis_df['RACE ETH'].apply(race_eth)\n",
    "\n",
    "\n",
    "state_num_list = [str(i) for i in [1, 4, 5, 6, 8, 9, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25,\n",
    "       26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 45, 47,\n",
    "       48, 49, 51, 53, 54, 55, '01', '04', '05', '06', '08', '09', '12',\n",
    "       '13', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24',\n",
    "       '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35',\n",
    "       '36', '37', '39', '40', '41', '42', '45', '47', '48', '49', '51',\n",
    "       '53', '54', '55']]\n",
    "\n",
    "analysis_df['FIPST'] = analysis_df[analysis_df['FIPST'].isin(state_num_list)]['FIPST']\n",
    "\n",
    "analysis_df['FIPST'] = analysis_df[analysis_df['FIPST'].notnull()]['FIPST']\n",
    "analysis_df['FIPST'] = pd.to_numeric(analysis_df['FIPST'])\n",
    "\n",
    "analysis_df['STATE'] = analysis_df['FIPST'].map(state_map)\n",
    "\n",
    "### Creating a minority column\n",
    "def is_minority(data):\n",
    "    if data == 'White':\n",
    "        return 'No'\n",
    "    else:\n",
    "        return 'Yes'\n",
    "    \n",
    "analysis_df['Minority'] = analysis_df['RACE ETH'].apply(is_minority)\n",
    "\n",
    "analysis_df['SECTOR'] = analysis_df['SECTOR'].astype('category')\n",
    "analysis_df[['ESTABLISHED', 'SCAMOUNT', 'FEDERAL','STATELOCAL', 'INDIVIDUALS', 'FAMILYBUS', 'ECOMMPCT', 'HUSBWIFE', 'HOMEBASED', 'FRANCHISE']] = \\\n",
    "analysis_df[['ESTABLISHED', 'SCAMOUNT', 'FEDERAL','STATELOCAL', 'INDIVIDUALS', 'FAMILYBUS', 'ECOMMPCT', 'HUSBWIFE', 'HOMEBASED', 'FRANCHISE']].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Yearly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2002.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe that sums business owner statistics by sector\n",
    "bysector_2002 = df_2002[(df_2002['Column Val']=='All owners of respondent firms') & \n",
    "                        (df_2002['OWNALL']!='0') & \n",
    "                        (df_2002['NAICS2002_MEANING']!='Total for all sectors')]\n",
    "\n",
    "bysector_2002 = bysector_2002.drop_duplicates(subset=['NAICS2002_MEANING', 'Column Val'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe that sums business owner statistics by sector\n",
    "bysector_2007 = df_2007[(df_2007['Column Val']=='All owners of respondent firms') & \n",
    "                        (df_2007['OWNALL']!='0') & (df_2007['NAICS2007_MEANING']!='Total for all sectors')\n",
    "                        & (df_2007['CBOGROUP_MEANING']=='All owners of respondent firms') & \n",
    "                        (df_2007['CBOSEX_MEANING']=='All owners of respondent firms')]\n",
    "\n",
    "bysector_2007 = bysector_2007.drop_duplicates(subset=['NAICS2007_MEANING', 'Column Val'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe that sums business owner statistics by sector\n",
    "bysector_2012 = df_2012[(df_2012['Column Val']=='Total reporting') & (df_2012['OWNALL']!='0') & \n",
    "                        (df_2012['NAICS2012_TTL']!='Total for all sectors') & \n",
    "                        (df_2012['CBOGROUP_TTL']=='All owners of respondent firms') & \n",
    "                        (df_2012['CBOSEX_TTL']=='All owners of respondent firms')]\n",
    "\n",
    "bysector_2012 = bysector_2012.drop_duplicates(subset=['NAICS2012_TTL', 'Column Val'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Makes the sectors consistent across the datasets\n",
    "sector_map_2002 = dict(zip(list(bysector_2002['NAICS2002_MEANING'].unique()),\n",
    "                           list(bysector_2012['NAICS2012_TTL'].unique()) ))\n",
    "\n",
    "bysector_2002['NAICS2002_MEANING'] = bysector_2002['NAICS2002_MEANING'].map(sector_map_2002)\n",
    "df_2002['NAICS2002_MEANING'] = df_2002['NAICS2002_MEANING'].map(sector_map_2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bysector_2012 = bysector_2012[['NAICS2012_TTL', 'YEAR','OWNALL', 'OWNALL_PCT', 'Column Val', 'Col Type']]\n",
    "bysector_2007 = bysector_2007[['NAICS2007_MEANING', 'YEAR','OWNALL', 'OWNALL_PCT', 'Column Val', 'Col Type']]\n",
    "\n",
    "bysector_2002.columns = ['NAICS_MEANING', 'YEAR', 'OWNALL', 'OWNALL_PCT', 'Column Val','Col Type']\n",
    "bysector_2007.columns = ['NAICS_MEANING', 'YEAR', 'OWNALL', 'OWNALL_PCT', 'Column Val','Col Type']\n",
    "bysector_2012.columns = ['NAICS_MEANING', 'YEAR', 'OWNALL', 'OWNALL_PCT', 'Column Val','Col Type']\n",
    "\n",
    "#combining the sector data for each of the three years\n",
    "bysector_combined = pd.concat([bysector_2002, bysector_2007, bysector_2012])\n",
    "bysector_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the datasets by minority and non-minorty\n",
    "df_2002_nomin = df_2002[df_2002['Column Val'] == 'White owners of respondent firms']\n",
    "df_2002_min = df_2002[(df_2002['Column Val'] == 'Asian owners of respondent firms') | (df_2002['Column Val'] == 'Asian owners of respondent firms') | (df_2002['Column Val'] == 'Black or African American owners of respondent firms') | (df_2002['Column Val'] == 'Hispanic owners of respondent firms') | (df_2002['Column Val'] == 'Native Hawaiian and Other Pacific Islander owners of respondent firms')]\n",
    "df_2002_nomin['CBOGROUP_MEANING'] = \"Nonminority\"\n",
    "df_2002_min['CBOGROUP_MEANING'] = \"Minority\"\n",
    "\n",
    "#total of minorities for each sector in 2012\n",
    "byrace_2012 = df_2012[(df_2012['Column Val']=='Total reporting') & (df_2012['OWNALL']!=0) & ((df_2012['CBOGROUP_TTL']=='Minority') | (df_2012['CBOGROUP_TTL']=='Nonminority')) & (df_2012['CBOSEX_TTL']=='All owners of respondent firms')]\n",
    "byrace_2012 = byrace_2012.drop_duplicates(subset=['NAICS2012_TTL', 'CBOGROUP_TTL', 'Column Val'], keep='first')\n",
    "\n",
    "#total of minorities for each sector in 2007\n",
    "byrace_2007 = df_2007[(df_2007['Column Val']=='All owners of respondent firms') & (df_2007['OWNALL']!=0) & ((df_2007['CBOGROUP_MEANING']=='Minority') | (df_2007['CBOGROUP_MEANING']=='Nonminority')) & (df_2007['CBOSEX_MEANING']=='All owners of respondent firms')]\n",
    "byrace_2007 = byrace_2007.drop_duplicates(subset=['NAICS2007_MEANING', 'CBOGROUP_MEANING', 'Column Val'], keep='first')\n",
    "\n",
    "#total of minorities for each sector in 2002\n",
    "byrace_2002_nomin = df_2002_nomin[(df_2002_nomin['OWNALL']!='0')]\n",
    "byrace_2002_nomin = byrace_2002_nomin.drop_duplicates(subset=['NAICS2002_MEANING', 'Column Val'], keep='first')\n",
    "byrace_2002_nomin = byrace_2002_nomin.groupby(\"NAICS2002_MEANING\", as_index=False).agg({'YEAR':'first', 'OWNALL':'sum', 'OWNALL_PCT': 'first', 'Column Val':'first', 'Col Type':'first', 'CBOGROUP_MEANING':'first'})\n",
    "byrace_2002_min = df_2002_min[(df_2002_min['OWNALL']!='0')]\n",
    "byrace_2002_min = byrace_2002_min.drop_duplicates(subset=['NAICS2002_MEANING', 'Column Val'], keep='first')\n",
    "byrace_2002_min = byrace_2002_min.groupby(\"NAICS2002_MEANING\", as_index=False).agg({'YEAR':'first', 'OWNALL':'sum', 'OWNALL_PCT': 'first', 'Column Val':'first', 'Col Type':'first', 'CBOGROUP_MEANING':'first'})\n",
    "\n",
    "#Standardizing the columns for each of the four dataframes\n",
    "byrace_2012 = byrace_2012[['NAICS2012_TTL', 'YEAR','OWNALL', 'OWNALL_PCT', 'Column Val', 'Col Type', 'CBOGROUP_TTL']]\n",
    "byrace_2007 = byrace_2007[['NAICS2007_MEANING', 'YEAR','OWNALL', 'OWNALL_PCT', 'Column Val', 'Col Type', 'CBOGROUP_MEANING']]\n",
    "\n",
    "byrace_2002_nomin.columns = ['NAICS_MEANING', 'YEAR', 'OWNALL', 'OWNALL_PCT', 'Column Val','Col Type', 'CBOGROUP_MEANING']\n",
    "byrace_2002_min.columns = ['NAICS_MEANING', 'YEAR', 'OWNALL', 'OWNALL_PCT', 'Column Val','Col Type', 'CBOGROUP_MEANING']\n",
    "byrace_2007.columns = ['NAICS_MEANING', 'YEAR', 'OWNALL', 'OWNALL_PCT', 'Column Val','Col Type', 'CBOGROUP_MEANING']\n",
    "byrace_2012.columns = ['NAICS_MEANING', 'YEAR', 'OWNALL', 'OWNALL_PCT', 'Column Val','Col Type', 'CBOGROUP_MEANING']\n",
    "\n",
    "#Concatenating all four of the datasets\n",
    "byrace_combined = pd.concat([byrace_2002_nomin, byrace_2002_min, byrace_2007, byrace_2012])\n",
    "byrace_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Visualization\n",
    "#### We start with a high level overview of all the data. To get an idea of overall trends we will look at the number of business owners in each sector for each year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of individual sector\n",
    "sectors = list(bysector_combined['NAICS_MEANING'].unique())\n",
    "\n",
    "fig = go.Figure(layout = go.Layout(\n",
    "    plot_bgcolor='rgba(0,0,0,0)'\n",
    "))\n",
    "\n",
    "#plots a line chart for the 3-year trend in each sector.\n",
    "for sector in sectors:\n",
    "    fig.add_trace(go.Scatter(x=pd.to_numeric(bysector_combined[bysector_combined['NAICS_MEANING'] == sector]['YEAR']),\n",
    "                             y=pd.to_numeric(bysector_combined[bysector_combined['NAICS_MEANING'] == sector]['OWNALL']), \n",
    "                             mode=\"lines+markers\", name=sector, visible=False,\n",
    "                             marker=dict(\n",
    "                                size=16,\n",
    "                                color=np.random.randn(500), #set color equal to a variable\n",
    "                                colorscale='Viridis', # one of plotly colorscales\n",
    "                                showscale=False\n",
    "                             ),\n",
    "                             line=dict(color='green', width=4),\n",
    "))\n",
    "\n",
    "#logic for the buttons in the dropdown menus. Only the data for the button selected shows up\n",
    "buttons= []\n",
    "for i in range(0, len(sectors)):\n",
    "    visible = [False]*len(sectors)\n",
    "    visible[i] = True\n",
    "    buttons.append(dict(label = sectors[i][0:30] + \"...\", method = 'update', args = [{'visible': visible}]))\n",
    "\n",
    "#updating the menu so it has the buttoms      \n",
    "fig.update_layout(updatemenus=list([dict(buttons = buttons)]))\n",
    "\n",
    "#Basic formatting\n",
    "fig.update_layout(width=1100, height=500,\n",
    "                  title_text = \"Number of Business Owners by Year\",\n",
    "                  xaxis_title=\"Year\",\n",
    "                  yaxis_title=\"Number of Business Owners\",\n",
    "                  showlegend=False)\n",
    "\n",
    "#Making custom x-axis values\n",
    "fig.update_layout(\n",
    "    xaxis = dict(\n",
    "        tickmode = 'array',\n",
    "        tickvals = [2002, 2007, 2012],\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_xaxes(showline=True, linewidth=2, linecolor='black', gridcolor='black')\n",
    "fig.update_yaxes(showline=True, linewidth=2, linecolor='black', gridcolor='black')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we we will look at the breakdown of total businesses by sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = bysector_combined['YEAR'].unique()\n",
    "bysector_combined = bysector_combined.sort_values(by=['YEAR', 'NAICS_MEANING'])\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for year in years:\n",
    "    fig.add_trace(\n",
    "        go.Pie(labels=bysector_combined[bysector_combined['YEAR']==year]['NAICS_MEANING'], \n",
    "               values=bysector_combined[bysector_combined['YEAR']==year]['OWNALL'], textinfo='label+percent',\n",
    "               hole=.3)\n",
    "    )\n",
    "\n",
    "#logic for the buttons in the dropdown menus. Only the data for the button selected shows up   \n",
    "buttons= []\n",
    "for i in range(0, len(years)):\n",
    "    visible = [False]*len(years)\n",
    "    visible[i] = True\n",
    "    buttons.append(dict(label = str(years[i]) , method = 'update', args = [{'visible': visible}]))\n",
    "\n",
    "#updating the menu so it has the buttoms      \n",
    "fig.update_layout(updatemenus=list([dict(buttons = buttons)]))\n",
    "\n",
    "fig.update_traces(textposition='inside', textinfo='percent')\n",
    "fig.update_layout(uniformtext_minsize=10, uniformtext_mode='hide')\n",
    "fig.update_layout(width=1100, height=500,\n",
    "                  title_text = \"Percent of Business Owners by Sector\"\n",
    "                  )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create a custom color palette of a given length. I didn't end up using this. \n",
    "def create_custom_palette(seaborn_scale, length):\n",
    "    rgb_colors = sns.color_palette(seaborn_scale, length)\n",
    "    hex_colors = [matplotlib.colors.to_hex(rgb) for rgb in rgb_colors]\n",
    "    return hex_colors\n",
    "\n",
    "print(create_custom_palette('rocket', 20))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And finally we will look at the trends for each sector and how the different for minorities and non-minorities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sectors = list(byrace_combined['NAICS_MEANING'].unique())\n",
    "\n",
    "#adds a plot for the total economic damages, regardless of event \n",
    "\n",
    "fig = go.Figure(layout = go.Layout(\n",
    "    plot_bgcolor='rgba(0,0,0,0)'\n",
    "))\n",
    "\n",
    "#loops through the the sectors and shows the trend in minority and non-minority business owners. \n",
    "for sector in sectors:\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=pd.to_numeric(byrace_combined[(byrace_combined['NAICS_MEANING'] == sector) & (byrace_combined['CBOGROUP_MEANING'] == \"Minority\")]['YEAR']),\n",
    "                             y=pd.to_numeric(byrace_combined[(byrace_combined['NAICS_MEANING'] == sector) & (byrace_combined['CBOGROUP_MEANING'] == \"Minority\")]['OWNALL']), \n",
    "                             mode=\"lines+markers\", name='Minority', visible=False,\n",
    "                             marker=dict(\n",
    "                                size=16,\n",
    "                                color='red',\n",
    "                                showscale=False\n",
    "                             ),\n",
    "                             line=dict(color='red', width=4),\n",
    "))\n",
    "\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=pd.to_numeric(byrace_combined[(byrace_combined['NAICS_MEANING'] == sector) & (byrace_combined['CBOGROUP_MEANING'] == \"Nonminority\")]['YEAR']),\n",
    "                             y=pd.to_numeric(byrace_combined[(byrace_combined['NAICS_MEANING'] == sector) & (byrace_combined['CBOGROUP_MEANING'] == \"Nonminority\")]['OWNALL']), \n",
    "                             mode=\"lines+markers\", name=\"Non-minority\", visible=False,\n",
    "                             marker=dict(\n",
    "                                size=16,\n",
    "                                color='green', #set color equal to a variable# one of plotly colorscales\n",
    "                                showscale=False\n",
    "                             ),\n",
    "                             line=dict(color='green', width=4),\n",
    "))\n",
    "\n",
    "    \n",
    "#This creates the dropdown menu and makes only one pair of traces visible at a time \n",
    "buttons = []\n",
    "for i in range(0, 2*len(sectors), 2):\n",
    "    visible = [False]*(2*len(sectors))\n",
    "    visible[i] = True\n",
    "    visible[i+1] = True\n",
    "    buttons.append(dict(label = sectors[int(i/2)][0:25]+ '...', method = 'update', args = [{'visible': visible}]))\n",
    "    \n",
    "fig.update_layout(updatemenus=list([dict(buttons = buttons)]))\n",
    "\n",
    "\n",
    "fig.update_layout(height=500, \n",
    "                  title_text = \"Number of Minority and Non-minority Owners by Year\",\n",
    "                  xaxis_title=\"Year\",\n",
    "                  yaxis_title=\"Number of Business Owners\",\n",
    "                  showlegend=True)\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis = dict(\n",
    "        tickmode = 'array',\n",
    "        tickvals = [2002, 2007, 2012],\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_xaxes(showline=True, linewidth=2, linecolor='black', gridcolor='black')\n",
    "fig.update_yaxes(showline=True, linewidth=2, linecolor='black', gridcolor='black')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which states havethe highest levels of minority business owenership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#grouping the data by state and by the race/ethnicity column\n",
    "group_analysis_data = analysis_df[['STATE', 'RACE ETH', 'SECTOR']]\n",
    "races_grouped = group_analysis_data.groupby(['STATE', 'RACE ETH'], as_index=False).count()\n",
    "\n",
    "#calculating the percentage total for each state\n",
    "state_totals = races_grouped.groupby('STATE', as_index=False).sum()\n",
    "races_grouped = races_grouped.merge(state_totals, on='STATE')\n",
    "races_grouped.columns = ['STATE', 'RACE ETH', 'Owners', 'State Total']\n",
    "races_grouped['Percent of State Total'] = (races_grouped['Owners'] / races_grouped['State Total'])* 100\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "groups = races_grouped['RACE ETH'].unique()\n",
    "\n",
    "#plots for each race/ethnicity group\n",
    "for group in groups:\n",
    "    fig.add_trace(go.Choropleth(\n",
    "        locations=races_grouped[races_grouped['RACE ETH'] == group]['STATE'], # Spatial coordinates\n",
    "        z = races_grouped[races_grouped['RACE ETH'] == group]['Percent of State Total'], # Data to be color-coded\n",
    "        locationmode = 'USA-states', # set of locations match entries in `locations`\n",
    "        colorscale = 'temps',\n",
    "        colorbar_title = \"Percent\",\n",
    "    ))\n",
    "\n",
    "#creating the buttons for the dropdown menu    \n",
    "buttons= []\n",
    "for i in range(0, len(groups)):\n",
    "    visible = [False]*len(groups)\n",
    "    visible[i] = True\n",
    "    buttons.append(dict(label = str(groups[i]) , method = 'update', args = [{'visible': visible}]))\n",
    "\n",
    "#updating the menu so it has the buttoms      \n",
    "fig.update_layout(updatemenus=list([dict(buttons = buttons)]))\n",
    "fig.update_layout(\n",
    "    title_text = 'Percent of Business Owners by State',\n",
    "    geo_scope='usa', # limite map scope to USA\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Clustering business ownerships by business characteristics and owner characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I want to explore creating clusters for different types of businesses based on traits like employment, payroll, receivables, whether the business was family owned, and so on. I then wanted to determine the breakdown of different characteristics of business owners by cluster. \n",
    "\n",
    "For this problem I decided to use K-Protoypes Clustering. This algorithm is a mixture of K-Means and K-Modes, and fits this problem well because it can cluster based on both numerical and categorical data. A downside of this algorithm is the computational complexity as you increase the number of data. Without a gpu and hours/days to train the model, I was not able to cluster based on all 1.5 million datapoints. Instead, I had to take random samples of the data. The most I could train with given the limitations of my hardware was 10,000, even after I split the work between all 6 of the processor cores on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the Cloumns we want to cluster by\n",
    "cluster_vars = ['EMPLOYMENT_NOISY', 'PAYROLL_NOISY', 'RECEIPTS_NOISY','FEDERAL','STATELOCAL',\n",
    "                'INDIVIDUALS', 'FAMILYBUS', 'HOMEBASED', 'FRANCHISE']\n",
    "cluster_df = analysis_df[cluster_vars]\n",
    "cluster_df = cluster_df.dropna(subset=cluster_vars)\n",
    "\n",
    "#Standardizing numerical data\n",
    "cluster_df['EMPLOYMENT_NOISY'] = preprocessing.scale(cluster_df['EMPLOYMENT_NOISY'])\n",
    "cluster_df['PAYROLL_NOISY'] = preprocessing.scale(cluster_df['PAYROLL_NOISY'])\n",
    "cluster_df['RECEIPTS_NOISY'] = preprocessing.scale(cluster_df['RECEIPTS_NOISY'])\n",
    "fit_sample = cluster_df.sample(n=10000, random_state=1)\n",
    "\n",
    "\n",
    "#Runs the K Prototypes algorithm with 1 through 6 clusters. \n",
    "start = time.time()\n",
    "cost = []\n",
    "for i in range(1,7):\n",
    "    model = KPrototypes(n_clusters=i, init='Huang', n_jobs=6, random_state=1) #I split the work between the 6 processor cores on \n",
    "    #my laptop\n",
    "    model.fit(fit_sample, categorical=[3,4,5,6,7,8]) #we specify which columns are categorical\n",
    "    cost.append(model.cost_)\n",
    "    \n",
    "end=time.time()\n",
    "print(\"Time to Run: \", end - start, \"seconds.\")\n",
    "\n",
    "fig = plt.figure()\n",
    "#Plots the cost vs. the number of clusters. The lower the cost, the better job it does clustering\n",
    "plt.plot(range(1,7), cost)\n",
    "fig.suptitle('Cost vs. Clusters')\n",
    "plt.xlabel('Clusters')\n",
    "plt.ylabel('Cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The model stops being able to initialize well clusters after 5, so we will use 5 clusters.\n",
    "#I used random states so I wouldn't get new outcomes each time I ran it.\n",
    "final_model = KPrototypes(n_clusters=5, init='Huang', n_jobs=6, random_state=2)\n",
    "final_model.fit(cluster_df.sample(n=10000, random_state=2), categorical=[3,4,5,6,7,8])\n",
    "\n",
    "results = final_model.predict(cluster_df, categorical=[3,4,5,6,7,8])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = analysis_df.dropna(subset=cluster_vars)\n",
    "cluster_column = results\n",
    "analysis_df['Cluster'] = cluster_column\n",
    "analysis_df['Cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_model.cluster_centroids_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do these clusters mean?\n",
    "\n",
    "#### Cluster 0:\n",
    "Number of businesses: 449927, Traits: Far below average employees, payroll and receivables; Most often is home-based, but not family owned or a franchise\n",
    "\n",
    "#### Cluster 1: \n",
    "Number of businesses: 572374, Traits: Slightly below average employees, payroll and receivables; More often is not family-owned, home-based, or a franchise. \n",
    "\n",
    "#### Cluster 2: \n",
    "Number of businesses: 20747, Traits: Slightly above average employees, payroll and receivables; More often is not family-owned, home-based, or a franchise\n",
    "\n",
    "#### Cluster 3:\n",
    "Number of businesses: 80, Traits: Far above average employees and receivables with slightly above average payroll; Most often is not family-owned, home-based, or a franchise.\n",
    "\n",
    "#### Cluster 4:\n",
    "Number of businesses: 1683, Traits: High above average employees, payroll and receivables; More often is not family-owned, home-based, or a franchise. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get an idea about the clusters, we can plot some data\n",
    "plot_df = analysis_df[(analysis_df['PAYROLL_NOISY'] < 1000000) & (analysis_df['RECEIPTS_NOISY'] < 8000000)]\n",
    "#transforming the data with the natural logarithm so it is less skewed.\n",
    "plot_df['log_payroll'] = np.log2(plot_df['PAYROLL_NOISY'])\n",
    "plot_df['log_receipts'] = np.log2(plot_df['RECEIPTS_NOISY'])\n",
    "fig = px.scatter(plot_df, x=\"log_payroll\", y=\"log_receipts\", color=\"Cluster\")\n",
    "fig.update_layout(title='Company Payroll vs. Receipts (Vizualisation of Clusters)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_percentages(df, column):\n",
    "    \"\"\"Function to determine the percentage of each unique value in the 'column' for each of the 5 clusters\"\"\"\n",
    "    clusters = [0,1,2,3,4]\n",
    "    \n",
    "    #finding the percentage breakdown for the total data set, regardless of cluter. \n",
    "    final = df[column].value_counts(normalize=True).reset_index()\n",
    "    final.columns = [column, 'Percent']\n",
    "    final['Cluster'] = 'Total'\n",
    "    \n",
    "    #creating a dataframe for the percentages of each cluster\n",
    "    for i in clusters:\n",
    "        cluster_df = df[df['Cluster'] == i]\n",
    "        cluster_perc = cluster_df[column].value_counts(normalize=True).reset_index()\n",
    "        cluster_perc.columns = [column, 'Percent']\n",
    "        cluster_perc['Cluster'] = \"Cluster \" + str(i)\n",
    "        \n",
    "        final = pd.concat([final, cluster_perc])\n",
    "    \n",
    "    final['Percent'] = final['Percent'] * 100\n",
    "    final[column] = final[column].astype(str)\n",
    "        \n",
    "    return final\n",
    "\n",
    "\n",
    "\n",
    "def graph_percentages(df, column):\n",
    "    \"\"\"Plots the percentage of the values in the given column present in each cluster\"\"\"\n",
    "    dataframe = cluster_percentages(df, column)\n",
    "    dataframe = dataframe.sort_values(by='Percent')\n",
    "    fig = go.Figure()\n",
    "    values = df[column].unique()\n",
    "    \n",
    "    #plots bar charts for each unique value in the column based on the percentage breakdown by cluster.\n",
    "    for v in values:\n",
    "        \n",
    "        #changes only the 'Total' values to red bars. \n",
    "        cluster_list = dataframe[dataframe[column] == v]['Cluster'].to_list()\n",
    "        colors = ['Blue'] * len(cluster_list)\n",
    "        colors_final = ['Red' if i == \"Total\" else \"Blue\" for i in cluster_list]\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Bar(x = dataframe[dataframe[column] == v]['Cluster'],\n",
    "                      y = dataframe[dataframe[column] == v]['Percent'],\n",
    "                      name=v,\n",
    "                      visible=False,\n",
    "                      marker_color=colors_final))\n",
    "    \n",
    "    #allows selections based on all of the values in the given column\n",
    "    buttons = []\n",
    "    for i in range(0, len(values)):\n",
    "        visible = [False]*len(values)\n",
    "        visible[i] = True\n",
    "        buttons.append(dict(label = values[i], method = 'update', args = [{'visible': visible}])) \n",
    "    \n",
    "    fig.update_layout(updatemenus=list([dict(buttons = buttons)]))\n",
    "    #formatting\n",
    "    fig.update_layout(height=500, \n",
    "                  title_text = \"Percent of Owners in Each Cluster\",\n",
    "                  xaxis_title=\"Clusters\",\n",
    "                  yaxis_title=\"Percent\",\n",
    "                  showlegend=False)\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_percentages(analysis_df, 'Minority')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Race/Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_percentages(analysis_df, 'RACE ETH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Born in the United States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_percentages(analysis_df, 'BORNUS1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The purpose of this project was to paint broad strokes about patterns that arise in business ownership in the United States. While we were interested in general trends, like the how the number of business owners were changing in certain sectors, the main goal of was to identify patterns in the demographics of business owners. \n",
    "\n",
    "In terms of the trend from 2002 to 2012, we observed many different combination of outcomes. For some sectors, like information and technology, both minority and non-minority ownership was increasing. In others, like real estate, both minority and nonminority ownership was increasing, but nonminority ownership was increasing much faster. Yet another outcome was the instance of minority ownership increasing and non-minority ownership decreasing.\n",
    "\n",
    "We also observed trends in geographic trends in the data. One takeaway was that even in states with high minority populations, one minority would tend to have a much larger presence in business ownership than the others. This points to the observation that while the United States is anecdotally considered a \"melting pot\", business ownership tends to stratify rather than mix together. \n",
    "\n",
    "Another important finding was was the demographic distribution amongst the clusters different types of businesses. While minorities make up about 18 percent of all business owners, they make up only about 5.6 percent of the owners of businesses belonging to cluster 4 (generally larger companies). Whether this discrepancy is a result of certain societal blockades towards minorities owning these more \"successful\" companies cannot be answered by this dataset, but the discrepancy is certainly there.  \n",
    "\n",
    "While I consider the research into this topic successful, there are definitely ways to improve. For one, I didn't have the hardware to take full advantage of the K-prototypes clustering algorithm. My ability to cluster was limited to random samples of data and all feature selection was done on a trial and error basis.\n",
    "Additionally, data on this topic is not as readily available as I believe it should be. As a result of this. I was limited to using data from 2007 to create clusters, as this was the only sizeable dataset available to the public. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zenodo Publication: https://zenodo.org/record/4321611#.X9e8CBNKhhE\n",
    "### Gitbub Publication: https://github.com/nickblackmore/DATS-6103-Individual-Project-3-Nicholas-Blackmore\n",
    "### Github.io Publication: https://nickblackmore.github.io/DATS-6103-Individual-Project-3-Nicholas-Blackmore-Web-Page"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
